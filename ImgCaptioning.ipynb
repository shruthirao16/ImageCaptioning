{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:07:48.551684Z",
     "iopub.status.busy": "2025-04-19T17:07:48.551137Z",
     "iopub.status.idle": "2025-04-19T17:07:48.560472Z",
     "shell.execute_reply": "2025-04-19T17:07:48.559832Z",
     "shell.execute_reply.started": "2025-04-19T17:07:48.551660Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:06:57.442169Z",
     "iopub.status.busy": "2025-04-19T17:06:57.441795Z",
     "iopub.status.idle": "2025-04-19T17:07:10.370800Z",
     "shell.execute_reply": "2025-04-19T17:07:10.370004Z",
     "shell.execute_reply.started": "2025-04-19T17:06:57.442150Z"
    }
   },
   "outputs": [],
   "source": [
    "#NLP\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, LSTM, add, Concatenate, Reshape, concatenate, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:07:10.372621Z",
     "iopub.status.busy": "2025-04-19T17:07:10.372086Z",
     "iopub.status.idle": "2025-04-19T17:07:10.393929Z",
     "shell.execute_reply": "2025-04-19T17:07:10.392733Z",
     "shell.execute_reply.started": "2025-04-19T17:07:10.372601Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "#CV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet201\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer\n",
    "\n",
    " \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:07:20.313600Z",
     "iopub.status.busy": "2025-04-19T17:07:20.313316Z",
     "iopub.status.idle": "2025-04-19T17:07:20.317901Z",
     "shell.execute_reply": "2025-04-19T17:07:20.317187Z",
     "shell.execute_reply.started": "2025-04-19T17:07:20.313579Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"dark\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:07:58.904870Z",
     "iopub.status.busy": "2025-04-19T17:07:58.904591Z",
     "iopub.status.idle": "2025-04-19T17:07:59.011728Z",
     "shell.execute_reply": "2025-04-19T17:07:59.011002Z",
     "shell.execute_reply.started": "2025-04-19T17:07:58.904849Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path = '/kaggle/input/flickr8k/Images'\n",
    "data = pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:08:32.746085Z",
     "iopub.status.busy": "2025-04-19T17:08:32.745807Z",
     "iopub.status.idle": "2025-04-19T17:08:35.044063Z",
     "shell.execute_reply": "2025-04-19T17:08:35.043221Z",
     "shell.execute_reply.started": "2025-04-19T17:08:32.746065Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualization\n",
    "def readImage(path,img_size=224):\n",
    "    img = load_img(path,color_mode='rgb',target_size=(img_size,img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255.\n",
    "    \n",
    "    return img\n",
    "\n",
    "def display_images(temp_df):\n",
    "    temp_df = temp_df.reset_index(drop=True)\n",
    "    plt.figure(figsize = (20 , 20))\n",
    "    n = 0\n",
    "    for i in range(15):\n",
    "        n+=1\n",
    "        plt.subplot(5 , 5, n)\n",
    "        plt.subplots_adjust(hspace = 0.7, wspace = 0.3)\n",
    "        image = readImage(f\"../input/flickr8k/Images/{temp_df.image[i]}\")\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"\\n\".join(wrap(temp_df.caption[i], 20)))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "display_images(data.sample(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:09:12.620153Z",
     "iopub.status.busy": "2025-04-19T17:09:12.619562Z",
     "iopub.status.idle": "2025-04-19T17:09:12.729171Z",
     "shell.execute_reply": "2025-04-19T17:09:12.728613Z",
     "shell.execute_reply.started": "2025-04-19T17:09:12.620131Z"
    }
   },
   "outputs": [],
   "source": [
    "#preprocessing captions text\n",
    "def text_preprocessing(data):\n",
    "    data['caption'] = data['caption'].apply(lambda x: x.lower())\n",
    "    data['caption'] = data['caption'].apply(lambda x: x.replace(\"[^A-Za-z]\",\"\"))\n",
    "    data['caption'] = data['caption'].apply(lambda x: x.replace(\"\\s+\",\" \"))\n",
    "    data['caption'] = data['caption'].apply(lambda x: \" \".join([word for word in x.split() if len(word)>1]))\n",
    "    data['caption'] = \"startseq \"+data['caption']+\" endseq\"\n",
    "\n",
    "    return data \n",
    "    \n",
    "data = text_preprocessing(data)\n",
    "\n",
    "captions = data['caption'].tolist()\n",
    "\n",
    "captions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:22:07.164689Z",
     "iopub.status.busy": "2025-04-19T17:22:07.164392Z",
     "iopub.status.idle": "2025-04-19T17:22:07.623284Z",
     "shell.execute_reply": "2025-04-19T17:22:07.622533Z",
     "shell.execute_reply.started": "2025-04-19T17:22:07.164654Z"
    }
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in captions)\n",
    "\n",
    "images = data['image'].unique().tolist()\n",
    "nimages = len(images)\n",
    "\n",
    "split_index = round(0.85*nimages)\n",
    "train_images = images[:split_index]\n",
    "val_images = images[split_index:]\n",
    "\n",
    "train = data[data['image'].isin(train_images)]\n",
    "test = data[data['image'].isin(val_images)]\n",
    "\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "tokenizer.texts_to_sequences([captions[1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:22:31.085341Z",
     "iopub.status.busy": "2025-04-19T17:22:31.084560Z",
     "iopub.status.idle": "2025-04-19T17:33:53.560049Z",
     "shell.execute_reply": "2025-04-19T17:33:53.559460Z",
     "shell.execute_reply.started": "2025-04-19T17:22:31.085304Z"
    }
   },
   "outputs": [],
   "source": [
    "#featue extraction\n",
    "model = DenseNet201()\n",
    "fe = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "img_size = 224\n",
    "features = {}\n",
    "for image in tqdm(data['image'].unique().tolist()):\n",
    "    img = load_img(os.path.join(image_path,image),target_size=(img_size,img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255.\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    feature = fe.predict(img, verbose=0)\n",
    "    features[image] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:37:17.955160Z",
     "iopub.status.busy": "2025-04-19T17:37:17.954657Z",
     "iopub.status.idle": "2025-04-19T17:37:17.973133Z",
     "shell.execute_reply": "2025-04-19T17:37:17.972362Z",
     "shell.execute_reply.started": "2025-04-19T17:37:17.955139Z"
    }
   },
   "outputs": [],
   "source": [
    "#data generation\n",
    "class CustomDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col, batch_size, directory, tokenizer, \n",
    "                 vocab_size, max_length, features,shuffle=True):\n",
    "    \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.n = len(self.df)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "    \n",
    "        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size,:]\n",
    "        X1, X2, y = self.__get_data(batch)        \n",
    "        return (X1, X2), y\n",
    "    \n",
    "    def __get_data(self,batch):\n",
    "        \n",
    "        X1, X2, y = list(), list(), list()\n",
    "        \n",
    "        images = batch[self.X_col].tolist()\n",
    "           \n",
    "        for image in images:\n",
    "            feature = self.features[image][0]\n",
    "            \n",
    "            captions = batch.loc[batch[self.X_col]==image, self.y_col].tolist()\n",
    "            for caption in captions:\n",
    "                seq = self.tokenizer.texts_to_sequences([caption])[0]\n",
    "\n",
    "                for i in range(1,len(seq)):\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]\n",
    "                    out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]\n",
    "                    X1.append(feature)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            \n",
    "        X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                \n",
    "        return X1, X2, y\n",
    "\n",
    "\n",
    "train_generator = CustomDataGenerator(df=train,X_col='image',y_col='caption',batch_size=64,directory=image_path,\n",
    "                                      tokenizer=tokenizer,vocab_size=vocab_size,max_length=max_length,features=features)\n",
    "\n",
    "validation_generator = CustomDataGenerator(df=test,X_col='image',y_col='caption',batch_size=64,directory=image_path,\n",
    "                                      tokenizer=tokenizer,vocab_size=vocab_size,max_length=max_length,features=features)\n",
    "# train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:37:23.700595Z",
     "iopub.status.busy": "2025-04-19T17:37:23.699788Z",
     "iopub.status.idle": "2025-04-19T17:37:24.075708Z",
     "shell.execute_reply": "2025-04-19T17:37:24.074960Z",
     "shell.execute_reply.started": "2025-04-19T17:37:23.700568Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:37:54.670377Z",
     "iopub.status.busy": "2025-04-19T17:37:54.669808Z",
     "iopub.status.idle": "2025-04-19T17:56:46.510261Z",
     "shell.execute_reply": "2025-04-19T17:56:46.509728Z",
     "shell.execute_reply.started": "2025-04-19T17:37:54.670355Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "input1 = Input(shape=(1920,))\n",
    "input2 = Input(shape=(max_length,))\n",
    "\n",
    "img_features = Dense(256, activation='relu')(input1)\n",
    "img_features_reshaped = Reshape((1, 256), input_shape=(256,))(img_features)\n",
    "\n",
    "sentence_features = Embedding(vocab_size, 256, mask_zero=False)(input2)\n",
    "merged = concatenate([img_features_reshaped,sentence_features],axis=1)\n",
    "sentence_features = LSTM(256)(merged)\n",
    "x = Dropout(0.5)(sentence_features)\n",
    "x = add([x, img_features])\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "caption_model = Model(inputs=[input1,input2], outputs=output)\n",
    "caption_model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the model checkpoint\n",
    "model_name = \"model.keras\"  # Update the extension to .keras\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_name,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = caption_model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint,earlystopping,learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T18:05:22.147780Z",
     "iopub.status.busy": "2025-04-19T18:05:22.147118Z",
     "iopub.status.idle": "2025-04-19T18:05:22.405329Z",
     "shell.execute_reply": "2025-04-19T18:05:22.404588Z",
     "shell.execute_reply.started": "2025-04-19T18:05:22.147752Z"
    }
   },
   "outputs": [],
   "source": [
    "#Learning Curve\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T18:13:29.781415Z",
     "iopub.status.busy": "2025-04-19T18:13:29.781120Z",
     "iopub.status.idle": "2025-04-19T18:13:31.177940Z",
     "shell.execute_reply": "2025-04-19T18:13:31.177322Z",
     "shell.execute_reply.started": "2025-04-19T18:13:29.781395Z"
    }
   },
   "outputs": [],
   "source": [
    "#Caption Generation\n",
    "import pickle\n",
    "\n",
    "# Save the tokenizer\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# Save the feature extractor model\n",
    "fe.save(\"feature_extractor.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T18:13:34.446781Z",
     "iopub.status.busy": "2025-04-19T18:13:34.446503Z",
     "iopub.status.idle": "2025-04-19T18:13:34.454543Z",
     "shell.execute_reply": "2025-04-19T18:13:34.453860Z",
     "shell.execute_reply.started": "2025-04-19T18:13:34.446762Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# load save files\n",
    "model_path = \"model.keras\"\n",
    "tokenizer_path = \"tokenizer.pkl\"\n",
    "feature_extractor_path = \"feature_extractor.keras\"\n",
    "\n",
    "\n",
    "def generate_and_display_caption(image_path, model_path, tokenizer_path, feature_extractor_path, max_length=34, img_size=224):\n",
    "    # Load the trained models and tokenizer\n",
    "    caption_model = load_model(model_path)\n",
    "    feature_extractor = load_model(feature_extractor_path)\n",
    "\n",
    "    with open(tokenizer_path, \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "\n",
    "    # Preprocess the image\n",
    "    img = load_img(image_path, target_size=(img_size, img_size))\n",
    "    img = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    image_features = feature_extractor.predict(img, verbose=0)  # Extract image features\n",
    "    \n",
    "    # Generate the caption\n",
    "    in_text = \"startseq\"\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = caption_model.predict([image_features, sequence], verbose=0)\n",
    "        yhat_index = np.argmax(yhat)\n",
    "        word = tokenizer.index_word.get(yhat_index, None)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += \" \" + word\n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    caption = in_text.replace(\"startseq\", \"\").replace(\"endseq\", \"\").strip()\n",
    "\n",
    "    # Display the image with the generated caption\n",
    "    img = load_img(image_path, target_size=(img_size, img_size))\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(caption, fontsize=16, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T18:13:52.681276Z",
     "iopub.status.busy": "2025-04-19T18:13:52.680800Z",
     "iopub.status.idle": "2025-04-19T18:14:15.190902Z",
     "shell.execute_reply": "2025-04-19T18:14:15.189988Z",
     "shell.execute_reply.started": "2025-04-19T18:13:52.681251Z"
    }
   },
   "outputs": [],
   "source": [
    "#Example\n",
    "image_path = \"/kaggle/input/flickr8k/Images/110595925_f3395c8bd6.jpg\"  # Replace with the path to the input image\n",
    "generate_and_display_caption(image_path, model_path, tokenizer_path, feature_extractor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
      "     -------------------------------------- 173.2/173.2 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-slugify in c:\\anaconda\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\lib\\site-packages (from kaggle) (3.4)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\anaconda\\lib\\site-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: bleach in c:\\anaconda\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\anaconda\\lib\\site-packages (from kaggle) (65.6.3)\n",
      "Requirement already satisfied: six>=1.10 in c:\\anaconda\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\anaconda\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: text-unidecode in c:\\anaconda\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\anaconda\\lib\\site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer in c:\\anaconda\\lib\\site-packages (from kaggle) (2.0.4)\n",
      "Requirement already satisfied: protobuf in c:\\anaconda\\lib\\site-packages (from kaggle) (4.25.3)\n",
      "Requirement already satisfied: webencodings in c:\\anaconda\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: packaging in c:\\anaconda\\lib\\site-packages (from bleach->kaggle) (22.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.7.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code downloaded to C:\\Users\\takka\\Downloads\\notebook423d727182.ipynb\n"
     ]
    }
   ],
   "source": [
    "!kaggle kernels pull shruthi369/notebook423d727182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
